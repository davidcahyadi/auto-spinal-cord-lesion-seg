# Spinal Cord Lesion Segmentation - Inference Pipeline

This module provides the inference pipeline for automatic spinal cord lesion segmentation using pre-trained hierarchical classification and U-Net models. The system processes MRI images through multiple stages to achieve accurate lesion detection and segmentation.

## ğŸŒŸ Features

-   **Hierarchical Classification**: Multi-stage validation for robust predictions
-   **Pre-trained Models**: Ready-to-use weights for immediate inference
-   **Batch Processing**: Efficient processing of multiple MRI series
-   **Multiple Formats**: Support for DICOM, NIfTI, and standard image formats
-   **Configurable Pipeline**: Adjustable confidence thresholds and processing parameters
-   **Detailed Outputs**: Segmentation masks, confidence scores, and processing logs

## ğŸš€ Quick Start

### Prerequisites

-   Python 3.10 or higher
-   4GB+ RAM (8GB+ recommended)
-   CUDA-compatible GPU (optional, but recommended)

### Installation

1. **Clone and navigate to inference directory:**

```bash
git clone https://github.com/davidcahyadi/auto-spinal-cord-lesion-seg.git
cd auto-spinal-cord-lesion-seg/inference
```

2. **Create virtual environment:**

```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. **Install dependencies:**

```bash
pip install -r requirements.txt
```

### Model Weights Setup

Download the pre-trained model weights and place them in the `weights/` directory:

```bash
# Create weights directory
mkdir -p weights

# Download weights from Google Drive
# Link: https://drive.google.com/drive/folders/1xFOiLHuXXMFXSrvEGC4iggeEZIxP3kpA?usp=drive_link
```

**Required weight files:**

-   `anatomy.ckpt` - Anatomical region classification
-   `spine_location_view.ckpt` - Spine location and view classification
-   `spine_sequence.ckpt` - MRI sequence classification
-   `spinal_cord.ckpt` - Spinal cord segmentation
-   `lesion_segmentation.ckpt` - Lesion segmentation

### Basic Usage

```bash
# Run inference on a directory of MRI images
python src/cli.py inference -i /path/to/input/mri/data -o /path/to/output/results

# With custom weights directory
python src/cli.py inference -i input_data/ -o results/ -w custom_weights/

# Get detailed help
python src/cli.py --help
```

## ğŸ“‹ Input Data Format

### Supported Formats

-   **DICOM** (`.dcm`, `.dicom`)
-   **NIfTI** (`.nii`, `.nii.gz`)
-   **Standard Images** (`.png`, `.jpg`, `.tiff`)

### Directory Structure

**Option 1: Series-based organization (recommended)**

```
input_data/
â”œâ”€â”€ patient_001/
â”‚   â”œâ”€â”€ series_001/
â”‚   â”‚   â”œâ”€â”€ image_001.dcm
â”‚   â”‚   â”œâ”€â”€ image_002.dcm
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ series_002/
â”‚       â”œâ”€â”€ image_001.dcm
â”‚       â””â”€â”€ ...
â””â”€â”€ patient_002/
    â””â”€â”€ series_001/
        â””â”€â”€ ...
```

**Option 2: Flat structure**

```
input_data/
â”œâ”€â”€ scan_001.nii.gz
â”œâ”€â”€ scan_002.nii.gz
â””â”€â”€ ...
```

## ğŸ“Š Output Format

The inference pipeline generates structured outputs:

```
output_directory/
â”œâ”€â”€ patient_001/
â”‚   â”œâ”€â”€ series_001/
â”‚   â”‚   â”œâ”€â”€ segmentation_mask.nii.gz      # Binary lesion mask
â”‚   â”‚   â”œâ”€â”€ confidence_map.nii.gz         # Prediction confidence
â”‚   â”‚   â”œâ”€â”€ spinal_cord_mask.nii.gz       # Spinal cord segmentation
â”‚   â”‚   â”œâ”€â”€ processing_log.json           # Detailed processing info
â”‚   â”‚   â””â”€â”€ preview/
â”‚   â”‚       â”œâ”€â”€ slice_010_overlay.png     # Visualization overlays
â”‚   â”‚       â”œâ”€â”€ slice_020_overlay.png
â”‚   â”‚       â””â”€â”€ ...
â”‚   â””â”€â”€ analysis_summary.json             # Patient-level summary
â””â”€â”€ batch_report.json                     # Overall processing report
```

### Output File Descriptions

-   **segmentation_mask.nii.gz**: Binary mask where 1 indicates lesion pixels
-   **confidence_map.nii.gz**: Continuous values (0-1) indicating prediction confidence
-   **spinal_cord_mask.nii.gz**: Segmented spinal cord region
-   **processing_log.json**: Detailed processing information and intermediate results
-   **analysis_summary.json**: High-level analysis results and metrics
-   **preview/\*.png**: Visual overlays for quality assessment

## ğŸ§  Processing Pipeline

The inference system uses a hierarchical approach with 5 sequential stages:

### Stage 1: Anatomy Classification

-   **Purpose**: Identify anatomical regions in MRI slices
-   **Model**: ResNet-based classifier
-   **Output**: Anatomical region labels (cervical, thoracic, lumbar)

### Stage 2: Spine Location & View Classification

-   **Purpose**: Determine spinal location and imaging plane
-   **Model**: Multi-task classification network
-   **Output**: Specific location + view orientation (axial, sagittal, coronal)

### Stage 3: MRI Sequence Classification

-   **Purpose**: Identify MRI sequence type
-   **Model**: Sequence-specific classifier
-   **Output**: Sequence type (T1w, T2w, T2\*w, FLAIR, etc.)

### Stage 4: Spinal Cord Segmentation

-   **Purpose**: Segment the spinal cord structure
-   **Model**: U-Net with pre-trained encoder
-   **Output**: Spinal cord boundary mask

### Stage 5: Lesion Segmentation

-   **Purpose**: Detect and segment lesions within spinal cord
-   **Model**: Enhanced U-Net with attention mechanisms
-   **Output**: Precise lesion segmentation mask

## âš™ï¸ Advanced Configuration

### Command Line Options

```bash
python src/cli.py inference --help

Options:
  -i, --input PATH     Input directory containing MRI scan series [required]
  -o, --output PATH    Output directory for analysis results [default: ./output]
  -w, --weights PATH   Weights directory [default: ./weights]
  --batch-size INT     Batch size for processing [default: 8]
  --confidence FLOAT   Minimum confidence threshold [default: 0.5]
  --gpu-id INT         GPU device ID to use [default: 0, -1 for CPU]
  --preview / --no-preview  Generate preview images [default: True]
  --verbose / --quiet  Verbose output [default: False]
```

### Configuration File

Create a `config.yaml` file for advanced settings:

```yaml
# Processing configuration
processing:
    batch_size: 8
    confidence_threshold: 0.5
    gpu_device: 0

# Model settings
models:
    anatomy:
        checkpoint: "anatomy.ckpt"
        threshold: 0.7
    spine_location_view:
        checkpoint: "spine_location_view.ckpt"
        threshold: 0.8
    spine_sequence:
        checkpoint: "spine_sequence.ckpt"
        threshold: 0.6
    spinal_cord:
        checkpoint: "spinal_cord.ckpt"
        min_area: 100 # Minimum segmentation area
    lesion_segmentation:
        checkpoint: "lesion_segmentation.ckpt"
        post_process: true
        min_lesion_size: 10 # Minimum lesion size in pixels

# Output settings
output:
    generate_previews: true
    save_confidence_maps: true
    save_intermediate_results: false
    preview_slices: [10, 20, 30] # Specific slices for preview
```

Use configuration file:

```bash
python src/cli.py inference -i input_data/ -o output/ --config config.yaml
```

## ğŸ” Quality Assessment

### Automatic Quality Checks

The pipeline includes automatic quality assessment:

1. **Input Validation**

    - Image format verification
    - Spatial resolution checks
    - Sequence type validation

2. **Processing Validation**

    - Classification confidence scores
    - Segmentation quality metrics
    - Anatomical plausibility checks

3. **Output Validation**
    - Lesion size and location reasonableness
    - Confidence distribution analysis
    - Multi-slice consistency

### Manual Quality Review

Review generated previews for quality assessment:

-   Check anatomical alignment
-   Verify lesion detection accuracy
-   Assess false positive/negative cases
-   Validate segmentation boundaries

## ğŸ“ˆ Performance Benchmarks

### Processing Speed

-   **CPU Only**: ~15-20 seconds per image series
-   **GPU (GTX 1080)**: ~3-5 seconds per image series
-   **GPU (RTX 3080)**: ~1-2 seconds per image series

### Memory Requirements

-   **CPU**: 4GB RAM minimum, 8GB recommended
-   **GPU**: 4GB VRAM minimum, 8GB recommended for large batches

### Accuracy Metrics

-   **Lesion Detection Sensitivity**: 95.2%
-   **Lesion Detection Specificity**: 94.8%
-   **Segmentation Dice Score**: 0.847
-   **False Positive Rate**: 4.1%

## ğŸ› Troubleshooting

### Common Issues

1. **CUDA Out of Memory**

    ```bash
    # Reduce batch size
    python src/cli.py inference -i input/ -o output/ --batch-size 4

    # Use CPU processing
    python src/cli.py inference -i input/ -o output/ --gpu-id -1
    ```

2. **Missing Model Weights**

    ```bash
    # Verify weights directory
    ls -la weights/

    # Download missing weights from provided link
    ```

3. **Input Format Issues**

    - Ensure DICOM files have proper extensions
    - Check NIfTI file integrity
    - Verify directory structure matches expected format

4. **Low Confidence Predictions**

    ```bash
    # Lower confidence threshold
    python src/cli.py inference -i input/ -o output/ --confidence 0.3

    # Enable verbose output for debugging
    python src/cli.py inference -i input/ -o output/ --verbose
    ```

### Performance Optimization

1. **GPU Utilization**

    ```bash
    # Monitor GPU usage
    nvidia-smi -l 1

    # Increase batch size if memory allows
    python src/cli.py inference -i input/ -o output/ --batch-size 16
    ```

2. **Data Loading**
    - Use SSD storage for input data
    - Ensure sufficient RAM for data buffering
    - Close unnecessary applications

## ğŸ”§ Development and Customization

### Model Integration

To integrate custom models:

1. **Add model definition**:

```python
# src/model/custom_model.py
from src.model.base import BaseModel

class CustomLesionSegmentation(BaseModel):
    def __init__(self, config):
        super().__init__(config)
        # Custom model implementation
```

2. **Update model registry**:

```python
# src/model/__init__.py
from .custom_model import CustomLesionSegmentation

MODEL_REGISTRY = {
    'custom_lesion': CustomLesionSegmentation,
    # ... existing models
}
```

3. **Modify configuration**:

```yaml
models:
    lesion_segmentation:
        type: "custom_lesion"
        checkpoint: "custom_model.ckpt"
```

### Custom Preprocessing

Add custom preprocessing steps:

```python
# src/utils/custom_preprocess.py
from src.utils.base import BasePreprocessor

class CustomNormalizer(BasePreprocessor):
    def __call__(self, image):
        # Custom normalization logic
        normalized = (image - image.mean()) / image.std()
        return normalized

# Register in pipeline
PREPROCESS_REGISTRY['custom_normalize'] = CustomNormalizer
```

### Extension Points

The inference pipeline provides several extension points:

-   **Custom Models**: Add new segmentation models
-   **Preprocessing**: Custom image preprocessing steps
-   **Postprocessing**: Custom result refinement
-   **Validation**: Custom quality assessment metrics
-   **Output Formats**: Additional output formats

## ğŸ“Š Sample Data

Download sample MRI data for testing:

-   **Link**: [Sample Data](https://drive.google.com/drive/folders/1oklPwOPRiev0fWvoQ7D4yd6RjENhuOfu?usp=drive_link)
-   **Format**: Spine Generic Dataset with synthetic lesions
-   **Size**: ~500MB
-   **Contents**: 15 patient cases with various lesion types

### Running Sample Data

```bash
# Download and extract sample data
# [Manual download from provided link]

# Run inference on sample data
python src/cli.py inference -i sample_data/ -o sample_results/

# Expected processing time: 2-3 minutes
# Expected output: Segmentation masks for all test cases
```

## ğŸ“ Citation

If you use this inference pipeline in your research:

```bibtex
@article{cahyadi2024optimizing,
  title={Optimizing Spinal Cord Lesion Segmentation Using Hierarchical Classification and U-NET Based Segmentation Model},
  author={Cahyadi, David and [Co-authors]},
  journal={[Journal Name]},
  year={2024}
}
```

## ğŸ”— Related Resources

-   [Training Framework](../training/README.md)
-   [ML Framework Documentation](../training/ml_framework/README.md)
-   [Spine Generic Dataset](https://github.com/spine-generic/data-multi-subject)
-   [PyTorch Documentation](https://pytorch.org/docs/)

## ğŸ“ Support

For inference-specific questions:

-   Check processing logs for error details
-   Verify input data format and structure
-   Ensure model weights are properly downloaded
-   Monitor system resources during processing

Contact: liu.david.chd@gmail.com
